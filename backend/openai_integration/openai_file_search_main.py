from __future__ import annotations

import argparse
from pathlib import Path

from openai_integration.openai_file_search_lib import (
    DEFAULT_MANIFEST_PATH,
    OpenAIFileSearchClient,
)


def main() -> None:
    parser = argparse.ArgumentParser(
        description=(
            "Run two-stage Responses flow from uploaded manifest + vector store top-k, "
            "then generate final response text"
        ),
    )
    parser.add_argument("--question", required=True, help="User question")
    parser.add_argument(
        "--manifest-path",
        default=str(DEFAULT_MANIFEST_PATH),
        help="JSON manifest path generated by openai_input_files_uploader",
    )
    parser.add_argument(
        "--model",
        default="gpt-4.1-mini",
        help="Responses API model name",
    )
    parser.add_argument(
        "--system-prompt",
        default=None,
        help="Optional system prompt",
    )
    parser.add_argument(
        "--top-k",
        type=int,
        default=3,
        help="Top-k vector store matches (default: 3)",
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Print intermediate ids and unmatched top matches",
    )
    args = parser.parse_args()

    client = OpenAIFileSearchClient(model=args.model)
    result = client.run_two_stage_response(
        question=args.question,
        manifest_path=Path(args.manifest_path).resolve(),
        system_prompt=args.system_prompt,
        top_k=args.top_k,
        model=args.model,
    )

    print(result.response_text)
    if args.debug:
        print("")
        print(f"first_response_id={result.first_response_id}")
        print(f"second_response_id={result.second_response_id}")
        print(f"uploaded_count={len(result.uploaded_files)}")
        print(f"top_matches_count={len(result.top_matches)}")
        print(f"unmatched_top_matches_count={len(result.unmatched_top_matches)}")


if __name__ == "__main__":
    main()
